{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OF7YtWNBlUML"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import zipfile\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ImageDataGenerator"
      ],
      "metadata": {
        "id": "pDBlIwRBlavD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "qNg-zp5-lWK2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 증강\n",
        "# 직접 가지고 가서 학습할 수 있도록 구현!!!!\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255. ,\n",
        "    validation_split = 0.2,\n",
        "    zoom_range = 0.2, # zoom_range 확대 정도, shear_range 기울기\n",
        ")\n",
        "valid_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255. ,\n",
        "    validation_split = 0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "lVQGswr1lWNC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input : (224,224,3) output(1,1,2)\n",
        "image_height = 224\n",
        "image_width = 224\n",
        "\n",
        "# train set : image_collection, train answer set : train_data_sub_folder\n",
        "train_data_sub_folder = \"/content/drive/MyDrive/2023_T_Academy/07_deep_learning/project/data/image_classification\"\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    directory = train_data_sub_folder,\n",
        "    subset = \"training\",\n",
        "    batch_size = 32,\n",
        "    seed = 42, shuffle = True,\n",
        "    class_mode = \"categorical\",\n",
        "    target_size = (image_height, image_width)\n",
        ")\n",
        "\n",
        "valid_generator = valid_datagen.flow_from_directory(\n",
        "    directory = train_data_sub_folder,\n",
        "    subset = \"validation\",\n",
        "    batch_size = 32,\n",
        "    seed = 42, shuffle = True,\n",
        "    class_mode = \"categorical\",\n",
        "    target_size = (image_height, image_width)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8wa2nzolWPK",
        "outputId": "7715cac1-95cd-4abc-d5bc-c3fcdc0cdf99"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 754 images belonging to 2 classes.\n",
            "Found 2938 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 논문 보고 구조 가져오기\n",
        "# input : (224,224,3) output(1,1,1000) -> input : (224,224,3) output(1,1,2)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D( input_shape = (224,224,3),kernel_size=(3,3), filters=6 ),\n",
        "\n",
        "    tf.keras.layers.Conv2D(\n",
        "        kernel_size = (5,5),\n",
        "        filters = 64,\n",
        "        strides = (2,2), # output 인 channel 사이즈를 반토막\n",
        "        padding = \"valid\",\n",
        "        activation = \"relu\", # 최근 추가\n",
        "    ),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(\n",
        "        kernel_size = (5,5),\n",
        "        filters = 128,\n",
        "        strides = (2,2), # output 인 channel 사이즈를 반토막\n",
        "        padding = \"valid\",\n",
        "        activation = \"relu\", # 최근 추가\n",
        "    ),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(\n",
        "        kernel_size = (5,5),\n",
        "        filters = 256,\n",
        "        strides = (2,2), # output 인 channel 사이즈를 반토막\n",
        "        padding = \"valid\",\n",
        "        activation = \"relu\", # 최근 추가\n",
        "    ),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2,2), strides=(2,2)),\n",
        "    tf.keras.layers.Flatten(), # 빼먹엇\n",
        "\n",
        "    tf.keras.layers.Dropout(rate=0.3),# dropout : 입력 뉴런의 30%를 학습 중에 무작위로 비활성화\n",
        "    tf.keras.layers.Dense( units = 2, activation=\"softmax\")\n",
        "])"
      ],
      "metadata": {
        "id": "RAbsEXLjlWRf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# batch로 넣기 , metrics=[\"precison\"]\n",
        "from keras.engine.training import optimizer\n",
        "model.compile( optimizer=\"Adam\",\n",
        "              loss = \"categorical_crossentropy\",\n",
        "              metrics=[tf.keras.metrics.Precision()]) # accuracy : 0~1\n",
        "\n",
        "history_generator = model.fit(train_generator,\n",
        "                    epochs=50)"
      ],
      "metadata": {
        "id": "chNTQqoFlWV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "425205c0-da9a-4aa0-b006-006508f6b4fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "24/24 [==============================] - 231s 9s/step - loss: 0.0256 - precision: 0.9894\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 83s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 79s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 78s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 82s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 81s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 78s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 77s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 76s 3s/step - loss: 0.0000e+00 - precision: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch로 넣기, metrics=[\"accuracy\"]\n",
        "from keras.engine.training import optimizer\n",
        "model.compile( optimizer=\"Adam\",\n",
        "              loss = \"categorical_crossentropy\",\n",
        "              metrics=[tf.keras.metrics.Precision()]) # accuracy : 0~1\n",
        "\n",
        "history_generator = model.fit(train_generator,\n",
        "                    epochs=50)"
      ],
      "metadata": {
        "id": "rlathRedlWT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 라벨링 안한 거 넣어서 확인해보기"
      ],
      "metadata": {
        "id": "siiowQjQwtX3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}