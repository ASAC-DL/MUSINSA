{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1VWpslK7t_fXx5aIw8Rh8ogVTsNA22luK","timestamp":1686731913266}],"gpuType":"T4","mount_file_id":"1VWpslK7t_fXx5aIw8Rh8ogVTsNA22luK","authorship_tag":"ABX9TyNBhtLYQhxs8yOWcx5Qld/j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":44,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O5jCNjYgD1Jt","executionInfo":{"status":"ok","timestamp":1686727376097,"user_tz":-540,"elapsed":5530,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}},"outputId":"120e9ace-ad00-4371-c3d5-d149afca4dd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 15978, done.\u001b[K\n","remote: Counting objects: 100% (147/147), done.\u001b[K\n","remote: Compressing objects: 100% (77/77), done.\u001b[K\n","remote: Total 15978 (delta 89), reused 111 (delta 70), pack-reused 15831\u001b[K\n","Receiving objects: 100% (15978/15978), 14.60 MiB | 19.39 MiB/s, done.\n","Resolving deltas: 100% (10962/10962), done.\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gitpython>=3.1.30 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (3.1.31)\n","Requirement already satisfied: matplotlib>=3.3 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (3.7.1)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.22.4)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (4.7.0.72)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (8.4.0)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (5.9.5)\n","Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.27.1)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.10.1)\n","Requirement already satisfied: thop>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (0.1.1.post2209072238)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (2.0.1+cu118)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (0.15.2+cu118)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (4.65.0)\n","Requirement already satisfied: ultralytics>=8.0.111 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (8.0.117)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (1.5.3)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (0.12.2)\n","Requirement already satisfied: setuptools>=65.5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 42)) (67.7.2)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython>=3.1.30->-r requirements.txt (line 5)) (4.0.10)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.0.7)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (0.11.0)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (4.39.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (1.4.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (23.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3->-r requirements.txt (line 6)) (2.8.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->-r requirements.txt (line 12)) (3.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7.0->-r requirements.txt (line 15)) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7.0->-r requirements.txt (line 15)) (16.0.5)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 27)) (2022.7.1)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython>=3.1.30->-r requirements.txt (line 5)) (5.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3->-r requirements.txt (line 6)) (1.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7.0->-r requirements.txt (line 15)) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7.0->-r requirements.txt (line 15)) (1.3.0)\n"]}],"source":["!git clone https://github.com/ultralytics/yolov5  && cd yolov5 && pip install -r requirements.txt"]},{"cell_type":"code","source":["!gdown 1WN1MYA4jQ-2toC2R6-kS9S0lIFm_o1fF"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"niVsRwFw4WBq","executionInfo":{"status":"ok","timestamp":1686728978950,"user_tz":-540,"elapsed":3472,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}},"outputId":"008af71b-2540-4713-80d0-f9e36f8784ba"},"execution_count":54,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1WN1MYA4jQ-2toC2R6-kS9S0lIFm_o1fF\n","To: /content/rm_images.zip\n","100% 48.5M/48.5M [00:01<00:00, 29.0MB/s]\n"]}]},{"cell_type":"code","source":["!unzip -qq \"/content/Clothing Detection.v1i.yolov5pytorch.zip\""],"metadata":{"id":"4UGXMcOM4btK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!gdown 1FWZXv4AOGSTUCHxurJM4gGNeyCGch-tj"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VISEo-C7D9DF","executionInfo":{"status":"ok","timestamp":1686718398138,"user_tz":-540,"elapsed":5058,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}},"outputId":"3fcfd9ba-7a57-45bc-c0ad-533badcd7e30"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1FWZXv4AOGSTUCHxurJM4gGNeyCGch-tj\n","To: /content/Clothing Detection.v1i.yolov5pytorch.zip\n","100% 221M/221M [00:04<00:00, 53.8MB/s]\n"]}]},{"cell_type":"code","source":["!unzip -qq \"/content/rm_images.zip\""],"metadata":{"id":"tZRXzsC2EBiH","executionInfo":{"status":"ok","timestamp":1686729041411,"user_tz":-540,"elapsed":665,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["!python yolov5/train.py --img 512 --batch 2 --epochs 2 --workers 2 --data data.yaml --cfg yolov5/models/yolov5s.yaml --name clothes_yolov5"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IJKKx1pREKA9","executionInfo":{"status":"ok","timestamp":1686727982189,"user_tz":-540,"elapsed":393749,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}},"outputId":"d964e19d-fbe6-46c9-a820-749fff7308ef"},"execution_count":48,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5/yolov5s.pt, cfg=yolov5/models/yolov5s.yaml, data=data.yaml, hyp=yolov5/data/hyps/hyp.scratch-low.yaml, epochs=2, batch_size=2, imgsz=512, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=None, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=2, project=yolov5/runs/train, name=clothes_yolov5, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ✅\n","YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 🚀 in ClearML\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 🚀 runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir yolov5/runs/train', view at http://localhost:6006/\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5s.pt to yolov5/yolov5s.pt...\n","100% 14.1M/14.1M [00:00<00:00, 131MB/s]\n","\n","Overriding model.yaml nc=80 with nc=10\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n","  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n","  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n","  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n","  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n","  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n","  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n","  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n","  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n","  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n"," 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n"," 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n"," 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n"," 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n"," 24      [17, 20, 23]  1     40455  models.yolo.Detect                      [10, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n","YOLOv5s summary: 214 layers, 7046599 parameters, 7046599 gradients, 16.0 GFLOPs\n","\n","Transferred 342/349 items from yolov5/yolov5s.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/train/labels.cache... 3257 images, 0 backgrounds, 0 corrupt: 100% 3257/3257 [00:00<?, ?it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels.cache... 536 images, 0 backgrounds, 0 corrupt: 100% 536/536 [00:00<?, ?it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m5.00 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset ✅\n","Plotting labels to yolov5/runs/train/clothes_yolov5/labels.jpg... \n","Image sizes 512 train, 512 val\n","Using 2 dataloader workers\n","Logging results to \u001b[1myolov5/runs/train/clothes_yolov5\u001b[0m\n","Starting training for 2 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        0/1     0.491G    0.07881      0.047    0.05155         11        512: 100% 1629/1629 [02:51<00:00,  9.52it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 134/134 [00:09<00:00, 13.90it/s]\n","                   all        536       2074      0.422      0.426      0.301      0.114\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        1/1     0.493G    0.05537    0.04111    0.03113          4        512: 100% 1629/1629 [02:39<00:00, 10.19it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 134/134 [00:11<00:00, 11.73it/s]\n","                   all        536       2074       0.33      0.609      0.423      0.179\n","\n","2 epochs completed in 0.098 hours.\n","Optimizer stripped from yolov5/runs/train/clothes_yolov5/weights/last.pt, 14.4MB\n","Optimizer stripped from yolov5/runs/train/clothes_yolov5/weights/best.pt, 14.4MB\n","\n","Validating yolov5/runs/train/clothes_yolov5/weights/best.pt...\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 134/134 [00:12<00:00, 10.68it/s]\n","                   all        536       2074      0.327      0.608      0.423      0.179\n","                   bag        536        292      0.312      0.798      0.515       0.21\n","                 dress        536        136      0.271      0.515      0.309      0.123\n","                   hat        536         86      0.673      0.431      0.543      0.181\n","                jacket        536        201      0.278      0.716      0.378      0.158\n","                 pants        536        122       0.35      0.943        0.6      0.315\n","                 shirt        536        357      0.257      0.796      0.328      0.119\n","                  shoe        536        519      0.339      0.829      0.572      0.217\n","                shorts        536        113      0.548      0.142      0.439      0.211\n","                 skirt        536        164      0.244      0.915      0.509      0.244\n","              sunglass        536         84          0          0     0.0355    0.00903\n","Results saved to \u001b[1myolov5/runs/train/clothes_yolov5\u001b[0m\n"]}]},{"cell_type":"code","source":["!python yolov5/detect.py --weights yolov5/runs/train/clothes_yolov5/weights/best.pt --img-size 512 --conf-thres 0.5 --iou-thres 0.5 --source /content/test/images --save-txt --save-conf --exist-ok"],"metadata":{"id":"EXmLb1NxMWiJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python yolov5/val.py --weights yolov5/runs/train/clothes_yolov5/weights/best.pt --data test.yaml --img-size 512"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3RHUi76YROe-","executionInfo":{"status":"ok","timestamp":1686727993059,"user_tz":-540,"elapsed":10589,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}},"outputId":"1780a9c9-3f1e-4cd6-e7db-1f5ec2282add"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=test.yaml, weights=['yolov5/runs/train/clothes_yolov5/weights/best.pt'], batch_size=32, imgsz=512, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n","Traceback (most recent call last):\n","  File \"/content/yolov5/val.py\", line 409, in <module>\n","    main(opt)\n","  File \"/content/yolov5/val.py\", line 380, in main\n","    run(**vars(opt))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n","    return func(*args, **kwargs)\n","  File \"/content/yolov5/val.py\", line 156, in run\n","    data = check_dataset(data)  # check\n","  File \"/content/yolov5/utils/general.py\", line 489, in check_dataset\n","    assert k in data, emojis(f\"data.yaml '{k}:' field missing ❌\")\n","AssertionError: data.yaml 'train:' field missing ❌\n"]}]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/ultralytics/yolov5/master/test.py\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VwBctzTLVZg9","executionInfo":{"status":"ok","timestamp":1686723153029,"user_tz":-540,"elapsed":469,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}},"outputId":"8b709924-6d6b-4290-b913-2ced377579c8"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-06-14 06:12:32--  https://raw.githubusercontent.com/ultralytics/yolov5/master/test.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2023-06-14 06:12:32 ERROR 404: Not Found.\n","\n"]}]},{"cell_type":"code","source":["!python yolov5/val.py --data test.yaml --weights yolov5/runs/best.pt --batch-size 8 --img-size 640 --iou-thres 0.7 --conf-thres 0.001"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uoXtLa8XVl7X","executionInfo":{"status":"ok","timestamp":1686729741449,"user_tz":-540,"elapsed":20701,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}},"outputId":"e0ddc938-edff-4597-819a-fdda719e0c7d"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=test.yaml, weights=['yolov5/runs/best.pt'], batch_size=8, imgsz=640, conf_thres=0.001, iou_thres=0.7, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=False, dnn=False\n","YOLOv5 🚀 v7.0-178-ga199480 Python-3.10.12 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","Fusing layers... \n","YOLOv5s summary: 157 layers, 7037095 parameters, 0 gradients, 15.8 GFLOPs\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/valid/labels... 268 images, 0 backgrounds, 0 corrupt: 100% 268/268 [00:00<00:00, 2000.77it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/valid/labels.cache\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 34/34 [00:08<00:00,  4.22it/s]\n","                   all        268       1046      0.577      0.682      0.649      0.352\n","                   bag        268        154      0.567      0.689      0.632      0.286\n","                 dress        268         54      0.676      0.667      0.681      0.446\n","                   hat        268         35      0.524      0.771      0.708      0.341\n","                jacket        268        107      0.791      0.607      0.751      0.428\n","                 pants        268         70      0.625      0.957      0.902      0.515\n","                 shirt        268        194      0.577      0.655      0.655      0.374\n","                  shoe        268        256      0.758      0.809      0.817      0.428\n","                shorts        268         47      0.538      0.447      0.502      0.261\n","                 skirt        268         93      0.543      0.882      0.704      0.411\n","              sunglass        268         36       0.17      0.333      0.131     0.0345\n","Speed: 0.5ms pre-process, 8.9ms inference, 3.4ms NMS per image at shape (8, 3, 640, 640)\n","Results saved to \u001b[1myolov5/runs/val/exp8\u001b[0m\n"]}]},{"cell_type":"code","source":["yaml_text = \"\"\"train: /content/train/images\n","val: /content/valid/images\n","test: /content/test/images\n","nc: 10\n","names: ['bag', 'dress', 'hat', 'jacket', 'pants', 'shirt', 'shoe', 'shorts', 'skirt', 'sunglass']\n","\"\"\""],"metadata":{"id":"ZAgYx3-FnYh6","executionInfo":{"status":"ok","timestamp":1686728111937,"user_tz":-540,"elapsed":2,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["with open(\"test.yaml\",\"w\") as f:\n","  f.write(yaml_text)"],"metadata":{"id":"KaufUPNDxMbL","executionInfo":{"status":"ok","timestamp":1686728113612,"user_tz":-540,"elapsed":2,"user":{"displayName":"jihun kim","userId":"10191965069606720128"}}},"execution_count":51,"outputs":[]}]}