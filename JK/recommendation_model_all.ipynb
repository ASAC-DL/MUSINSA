{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3, preprocess_input\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input as preprocess_input_irv2\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "import os\n",
    "from glob import glob\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "  def __init__(self):\n",
    "    # Use VGG-16 as the architecture and ImageNet for the weight\n",
    "    base_model = VGG16(weights='imagenet')\n",
    "    # Customize the model to return features from fully-connected layer\n",
    "    self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "  def extract(self, img):\n",
    "  # Resize the image\n",
    "    img = img.resize((224, 224))\n",
    "\n",
    "    # Convert the image color space\n",
    "    img = img.convert('RGB')\n",
    "    # Reformat the image\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    # Extract Features\n",
    "    feature = self.model.predict(x)[0]\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_image_path = r\"merged_tot_image\"\n",
    "file_list = os.listdir(tot_image_path)\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_feature_path = \"merged_features\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "img_paths = []\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "# Save Image Feature Vector with Database Images\n",
    "\n",
    "for i in tqdm(range(1609, 10000)):\n",
    "  try:\n",
    "    image_path = tot_image_path + '/{}'.format(file_list[i]) # 파일 속 이미지 파일 이름\n",
    "    img_paths.append(image_path)\n",
    "\n",
    "    # Extract Features\n",
    "    feature = fe.extract(img=Image.open(image_path))\n",
    "\n",
    "    features.append(feature)\n",
    "    # Save the Numpy array (.npy) on designated path\n",
    "    feature_path = tot_feature_path +\"/\" + file_list[i].strip('.jpg') + \".npy\"     # Feature를 저장할 폴더 경로\n",
    "    np.save(feature_path, feature)\n",
    "  except Exception as e:\n",
    "    print('예외가 발생했습니다.', e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2: 유클리디안 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the image query\n",
    "img = Image.open(\"2928418_36357327_0.jpg\") # 알고 싶은 이미지 경로\n",
    "# Extract its features\n",
    "query = fe.extract(img)\n",
    "# Calculate the similarity (distance) between images # 유사도 비교\n",
    "dists = np.linalg.norm(features - query, axis = 1)\n",
    "\n",
    "# Extract 30 images that have lowest distance # 가장 가까운 30개의 사진 추천\n",
    "ids = np.argsort(dists)[:30]\n",
    "\n",
    "scores = [(dists[id], img_paths[id], id) for id in ids]\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + score[1].split('/')[-1][:4]\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine similarity : 코사인 유사도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the image query\n",
    "img = Image.open(\"2928418_36357327_0.jpg\") # 알고 싶은 이미지 경로\n",
    "# Extract its features\n",
    "query = fe.extract(img)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate the cosine similarity between images\n",
    "sims = cosine_similarity(features, query.reshape(1, -1))\n",
    "\n",
    "# Convert similarity scores to distance\n",
    "dists = 1 - sims.flatten()\n",
    "\n",
    "# Extract 30 images that have lowest distance # 가장 가까운 30개의 사진 추천\n",
    "ids = np.argsort(dists)[:30][::-1]\n",
    "\n",
    "scores = [(dists[id], img_paths[id], id) for id in ids]\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + score[1].split('/')[-1][:4]\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 : 맨해튼 거리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the image query\n",
    "img = Image.open(\"2928418_36357327_0.jpg\") # 알고 싶은 이미지 경로\n",
    "# Extract its features\n",
    "query = fe.extract(img)\n",
    "\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "\n",
    "# Calculate the cosine similarity between images\n",
    "sims = manhattan_distances(features, query.reshape(1, -1))\n",
    "\n",
    "# Convert similarity scores to distance\n",
    "dists = 1 - sims.flatten()\n",
    "\n",
    "# Extract 30 images that have lowest distance # 가장 가까운 30개의 사진 추천\n",
    "ids = np.argsort(dists)[:30][::-1]\n",
    "\n",
    "scores = [(dists[id], img_paths[id], id) for id in ids]\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + score[1].split('/')[-1][:4]\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19\n",
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        base_model = VGG19(weights='imagenet')\n",
    "        # Customize the model to return features from fully-connected layer\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('predictions').output)\n",
    "\n",
    "    def extract(self, img):\n",
    "      # Resize the image\n",
    "        img = img.resize((224, 224))\n",
    "        # Convert the image color space\n",
    "        img = img.convert('RGB')\n",
    "        # Reformat the image\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # Extract Features\n",
    "        feature = self.model.predict(x)[0]\n",
    "        return feature "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "img_paths = []\n",
    "files = []\n",
    "\n",
    "# 파일 경로 설정\n",
    "fe = FeatureExtractor()\n",
    "# Save Image Feature Vector with Database Images\n",
    "for i in range(9990,10010):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    try:\n",
    "        path = 'C:/Users/NT550/Desktop/DL_project/image'\n",
    "        os.chdir(path)\n",
    "        files = os.listdir(path)\n",
    "        image_path = 'C:/Users/NT550/Desktop/DL_project/image/{}'.format(files[i]) # 파일 속 이미지 파일 이름\n",
    "        img_paths.append(image_path)\n",
    "        \n",
    "        # Extract Features\n",
    "        feature = fe.extract(img=Image.open(image_path))\n",
    "            \n",
    "        features.append(feature)\n",
    "        # Save the Numpy array (.npy) on designated path\n",
    "     # Feature를 저장할 폴더 경로 설정(폴더 생성 후 경로 설정)\n",
    "        feature_path = \"C:/Users/NT550/Desktop/DL_project/features/features\" + files[i].strip('.jpg') + \".npy\"\n",
    "        np.save(feature_path, feature)\n",
    "    except Exception as e:\n",
    "        print('예외가 발생했습니다.', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "features_vgg19 = []\n",
    "file_list = os.listdir('C:/Users/NT550/Desktop/DL_project/features_VGG19')\n",
    "for file in file_list[:10000]:\n",
    "    feature = np.load(f'C:/Users/NT550/Desktop/DL_project/features_VGG19/{file}')\n",
    "    features_vgg19.append(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = []\n",
    "path = \"C:/Users/NT550/Desktop/DL_project/image\"\n",
    "image_list = os.listdir(path)\n",
    "for file in image_list[:10000]:\n",
    "    image = path + '/' + file\n",
    "    image_path.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open(\"C:/Users/NT550/Desktop/DL_project/bg_1.jpg\") # 알고 싶 이미지 경로\n",
    "fe = FeatureExtractor()\n",
    "query_vgg19 = fe.extract(img)\n",
    "dists_vgg19 = np.linalg.norm(features_vgg19 - query_vgg19, axis=1)\n",
    "dists_vgg19_cosine = cosine_distances(features_vgg19, query_vgg19.reshape(1, -1)).ravel()\n",
    "dists_vgg19_manhattan = manhattan_distances(features_vgg19, query_vgg19.reshape(1, -1)).ravel()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the image query\n",
    "img = Image.open(\"C:/Users/NT550/Desktop/DL_project/bg_0.jpg\") # 알고 싶은 이미지 경로\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "# Extract its features\n",
    "query = fe.extract(img)\n",
    "\n",
    "# Calculate the similarity (distance) between images using cosine distance\n",
    "dists = cosine_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "# Extract 30 images that have lowest distance\n",
    "ids = np.argsort(dists)[:30]\n",
    "\n",
    "scores = [(dists[id], image_path[id], id) for id in ids]\n",
    "\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + score[1].split('/')[-1][:4]\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 맨해튼"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Insert the image query\n",
    "img = Image.open(\"C:/Users/NT550/Desktop/DL_project/bg_0.jpg\") # 알고 싶은 이미지 경로\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "# Extract its features\n",
    "query = fe.extract(img)\n",
    "\n",
    "# Calculate the similarity (distance) between images using Manhattan distance\n",
    "dists = manhattan_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "# Extract 30 images that have lowest distance\n",
    "ids = np.argsort(dists)[:30]\n",
    "\n",
    "scores = [(dists[id], image_path[id], id) for id in ids]\n",
    "\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + score[1].split('/')[-1][:4]\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "  def __init__(self):\n",
    "    base_model = InceptionV3(weights='imagenet')\n",
    "    # Customize the model to return features from fully-connected layer\n",
    "    self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('predictions').output) \n",
    "    # InceptionV3 : ['batch_normalization_93', 'activation_85', 'mixed9_1', 'concatenate_1', 'activation_93', 'mixed10', 'avg_pool', 'predictions'].\n",
    "\n",
    "  def extract(self, img):\n",
    "  # Resize the image\n",
    "    img = img.resize((299,299)) \n",
    "    # Convert the image color space\n",
    "    img = img.convert('RGB')\n",
    "    # Reformat the image\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    # Extract Features\n",
    "    feature = self.model.predict(x)[0]\n",
    "    return feature  # feature / np.linalg.norm(feature)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "img_paths = []\n",
    "\n",
    "fe = FeatureExtractor()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 폴더에 저장되어 있는 features npy 가져오기\n",
    "features_dir = r\"C:\\Users\\NT550009\\Desktop\\features\"\n",
    "os.chdir(features_dir)\n",
    "feature_list = os.listdir(features_dir)\n",
    "print(feature_list)\n",
    "# ['2734389_3.npy', '2734389_4.npy', '2734391_0.npy', \n",
    "\n",
    "# 각 파일을 읽어서 features에 추가합니다.\n",
    "for file_path in feature_list:\n",
    "    data = np.load(file_path)\n",
    "    features.append(data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the image query\n",
    "img = Image.open(r\"C:\\Users\\NT550009\\Desktop\\recommendation\\cropped_image_2.jpg\") # 알고 싶은 이미지 경로\n",
    "# query 에서 feature 추출\n",
    "query = fe.extract(img) \n",
    "# Calculate the similarity (distance) between images # 유사도 비교\n",
    "dists = np.linalg.norm(features - query, axis=1) \n",
    "\n",
    "# Extract 30 images that have lowest distance \n",
    "# 가장 가까운 30개의 사진 추천\n",
    "ids = np.argsort(dists)[:30]\n",
    "\n",
    "scores = [(dists[id], img_paths[id], id) for id in ids]\n",
    "\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8)) # figsize 설정\n",
    "for a in range(5*6): # 30개의 서브플롯\n",
    "    score = scores[a] # 거리유사도가 낮은 순서대로 \n",
    "    axes.append(fig.add_subplot(5, 6, a+1)) # 채워진 서브플롯 위치 저장\n",
    "    \n",
    "    string = score[1]\n",
    "    pattern = r'[^/\\\\]+(?=\\.[^.]+$)'\n",
    "    match = re.search(pattern, string)\n",
    "    if match:\n",
    "        product_num = match.group()\n",
    "      \n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + str(product_num)\n",
    "    \n",
    "    axes[-1].set_title(subplot_title) \n",
    "    plt.axis('off') # 현재 서브플롯의 축에 대한 눈금과 레이블을 제거\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "# cosine similarity\n",
    "dists = cosine_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "\n",
    "# Extract 30 images that have lowest distance \n",
    "# 가장 가까운 30개의 사진 추천\n",
    "ids = np.argsort(dists)[:30]\n",
    " \n",
    "scores = [(dists[id], img_paths[id], id) for id in ids]\n",
    "\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/m\" + str(score[2]+1)\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boston\n",
    "distance = np.sum(np.abs(features - query))\n",
    "\n",
    "\n",
    "dists = manhattan_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "dists = np.sum(np.abs(features - query), axis=1)\n",
    "\n",
    "# Extract 30 images that have lowest distance \n",
    "# 가장 가까운 30개의 사진 추천\n",
    "ids = np.argsort(dists)[:30]\n",
    "\n",
    "\n",
    "scores = [(dists[id], img_paths[id], id) for id in ids]\n",
    "\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/m\" + str(score[2]+1)\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    def __init__(self):\n",
    "        base_model = ResNet50(weights='imagenet')\n",
    "        # Customize the model to return features from fully-connected layer\n",
    "        self.model = Model(inputs=base_model.input, outputs=base_model.get_layer('predictions').output)\n",
    "\n",
    "    def extract(self, img):\n",
    "      # Resize the image\n",
    "        img = img.resize((224, 224))\n",
    "        # Convert the image color space\n",
    "        img = img.convert('RGB')\n",
    "        print(img)\n",
    "        # Reformat the image\n",
    "        x = image.img_to_array(img)\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        # Extract Features\n",
    "        feature = self.model.predict(x)[0]\n",
    "        return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "img_paths = []\n",
    "files = []\n",
    "\n",
    "# 파일 경로 설정\n",
    "\n",
    "\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "# Save Image Feature Vector with Database Images\n",
    "for i in range(31082,45000):\n",
    "    if i%100 == 0:\n",
    "        print(i)\n",
    "    try:\n",
    "        path = 'C:/Users/NT550/Desktop/DL_project/image'\n",
    "\n",
    "        os.chdir(path)\n",
    "        files = os.listdir(path)\n",
    "        image_path = 'C:/Users/NT550/Desktop/DL_project/image/{}'.format(files[i]) # 파일 속 이미지 파일 이름\n",
    "        img_paths.append(image_path)\n",
    "        \n",
    "        # Extract Features\n",
    "        feature = fe.extract(img=Image.open(image_path))\n",
    "            \n",
    "        features.append(feature)\n",
    "        # Save the Numpy array (.npy) on designated path\n",
    "     # Feature를 저장할 폴더 경로 설정(폴더 생성 후 경로 설정)\n",
    "        feature_path = \"C:/Users/NT550/Desktop/DL_project/features/features\" + files[i].strip('.jpg') + \".npy\"\n",
    "        np.save(feature_path, feature)\n",
    "    except Exception as e:\n",
    "        print('예외가 발생했습니다.', e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그냥 유사도\n",
    "img = Image.open(\"C:/Users/NT550/Desktop/DL_project/bg_0.jpg\") # 알고 싶 이미지 경로\n",
    "fe = FeatureExtractor()\n",
    "# Extract its features\n",
    "query = fe.extract(img)\n",
    "\n",
    "# 유사도 비교 (L2 norm)\n",
    "dists = np.linalg.norm(features - query, axis=1)\n",
    "\n",
    "# 코사인 유사도\n",
    "dists_cosine = cosine_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "# 유클리디안 유사도\n",
    "dists_euclidean = euclidean_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "# 맨허튼 유사도\n",
    "dists_manhattan = manhattan_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "\n",
    "# Extract 30 images that have lowest distance # 가장 가까운 30개의 사진 추천\n",
    "ids = np.argsort(dists)[:30]\n",
    "\n",
    "scores = [(dists[id], image_path[id], id) for id in ids]\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + score[1].split('/')[-1][:4]\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 코사인 유사도\n",
    "img = Image.open(\"C:/Users/NT550/Desktop/DL_project/bg_0.jpg\") # 알고 싶 이미지 경로\n",
    "fe = FeatureExtractor()\n",
    "# Extract its features\n",
    "query = fe.extract(img)\n",
    "\n",
    "# Calculate the similarity (distance) between images # 유사도 비교 (L2 norm)\n",
    "dists = cosine_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "# Extract 30 images that have lowest distance # 가장 가까운 30개의 사진 추천\n",
    "ids = np.argsort(dists)[:30]\n",
    "\n",
    "scores = [(dists[id], image_path[id], id) for id in ids]\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + score[1].split('/')[-1][:4]\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## manhattan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import manhattan_distances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Insert the image query\n",
    "img = Image.open(\"C:/Users/NT550/Desktop/DL_project/bg_0.jpg\") # 알고 싶은 이미지 경로\n",
    "\n",
    "fe = FeatureExtractor()\n",
    "# Extract its features\n",
    "query = fe.extract(img)\n",
    "\n",
    "# Calculate the similarity (distance) between images using Manhattan distance\n",
    "dists = manhattan_distances(features, query.reshape(1, -1)).ravel()\n",
    "\n",
    "# Extract 30 images that have lowest distance\n",
    "ids = np.argsort(dists)[:30]\n",
    "\n",
    "scores = [(dists[id], image_path[id], id) for id in ids]\n",
    "\n",
    "# Visualize the result\n",
    "axes=[]\n",
    "fig=plt.figure(figsize=(8,8))\n",
    "for a in range(5*6):\n",
    "    score = scores[a]\n",
    "    axes.append(fig.add_subplot(5, 6, a+1))\n",
    "    subplot_title=str(round(score[0],2)) + \"/\" + score[1].split('/')[-1][:4]\n",
    "    axes[-1].set_title(subplot_title)  \n",
    "    plt.axis('off')\n",
    "    plt.imshow(Image.open(score[1]))\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
